{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Tokens: [11, 13, 5, 8, 1, 7, 2, 12, 10, 4, 9, 3, 6, 60]\n",
      "Decoded Text: Hello, how are you doing today? This is a simple example.\n",
      "Subwords:\n",
      "you_\n",
      "today\n",
      "simple_\n",
      "is_\n",
      "how_\n",
      "example\n",
      "doing_\n",
      "are_\n",
      "a_\n",
      "This_\n",
      "Hello\n",
      "? \n",
      ", \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Sample text\n",
    "text = \"Hello, how are you doing today? This is a simple example.\"\n",
    "\n",
    "# Create and train a subword text encoder\n",
    "encoder = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus([text], target_vocab_size=2**12)\n",
    "\n",
    "# Encode text into subword tokens\n",
    "encoded_tokens = encoder.encode(text)\n",
    "print(\"Encoded Tokens:\", encoded_tokens)\n",
    "\n",
    "# Decode subword tokens back to text\n",
    "decoded_text = encoder.decode(encoded_tokens)\n",
    "print(\"Decoded Text:\", decoded_text)\n",
    "\n",
    "# Print the subwords generated by the encoder\n",
    "subwords = encoder.subwords\n",
    "print(\"Subwords:\")\n",
    "for subword in subwords:\n",
    "    print(subword)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:48:47.696221685Z",
     "start_time": "2023-11-03T10:48:47.638039754Z"
    }
   },
   "id": "47e279096d1e0660"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(text):\n",
    "    # text = re.sub(r\"_\", \" \", text)\n",
    "    # remove `~@#$%^&*()_+=/><':;}{[]|\\ “‘\n",
    "    # text = re.sub(r\"([“‘`~@#$%^&*()_+=/><':;}{\\[\\]\\\\|])\", \" \", text)\n",
    "    text.strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_sentences(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append(preprocess_sentence(sentence))\n",
    "    return new_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:41:02.792518977Z",
     "start_time": "2023-11-03T10:41:02.734860258Z"
    }
   },
   "id": "ba43b137fbdc4517"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-03T10:41:02.795074459Z",
     "start_time": "2023-11-03T10:41:02.775519591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['your_', 'what_', 'what', 'say_', 'name', 'is_']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "data = ['what is your name', 'say what']\n",
    "data = preprocess_sentences(data)\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    data,\n",
    "    target_vocab_size=2**32,\n",
    ")\n",
    "print(tokenizer.subwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "This is a text\n",
      "with 123 numbers and some special characters!@#$%^&*.\n",
      "\n",
      "Text after removing non-alphabetic characters:\n",
      "This is a text with     numbers and some special characters         \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_non_alphabetic(text):\n",
    "    # Keep only alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"This is a text\\nwith 123 numbers and some special characters!@#$%^&*.\"\n",
    "cleaned_text = remove_non_alphabetic(input_text)\n",
    "\n",
    "print(\"Original text:\")\n",
    "print(input_text)\n",
    "\n",
    "print(\"\\nText after removing non-alphabetic characters:\")\n",
    "print(cleaned_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T16:39:13.232623931Z",
     "start_time": "2023-11-21T16:39:13.231365135Z"
    }
   },
   "id": "63d5fce5515f1d48"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text with and Hello but not these word Äpple och päron är frukt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Some text with hello123 and Hello&^ but not these: word, word2! Äpple och päron är frukt.\"\n",
    "\n",
    "filtered_words = re.findall(r'\\b(?![\\d\\W“‘`~!@#$%^&*?()_+=/><\\'.,:;}{\\[\\]\\\\|-]+)[a-zA-ZäöåÄÖÅ]+\\b', text)\n",
    "filtered_sentence = ' '.join(filtered_words)\n",
    "\n",
    "print(filtered_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:48:39.098710730Z",
     "start_time": "2023-12-01T15:48:39.044652801Z"
    }
   },
   "id": "5fae714871ee1f17"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Svensk text att koda.\n",
      "Encoded text: [6, 1, 106, 125, 125, 41, 116, 120, 109, 106, 55]\n",
      "Decoded text: Svensk text att koda.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Assuming you have a list of strings containing Swedish text\n",
    "corpus = [\"Svensk text här.\", \"Lite mer svensk text möjligheten .\"]\n",
    "\n",
    "# Build a SubwordTextEncoder from the corpus\n",
    "encoder = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(corpus, target_vocab_size=8000)\n",
    "\n",
    "# Save the encoder to a file\n",
    "encoder.save_to_file('swedish_encoder')\n",
    "\n",
    "# Load the encoder back\n",
    "loaded_encoder = tfds.deprecated.text.SubwordTextEncoder.load_from_file('swedish_encoder')\n",
    "\n",
    "# Example encoding and decoding\n",
    "text = \"Svensk text att koda.\"\n",
    "encoded_text = loaded_encoder.encode(text)\n",
    "decoded_text = loaded_encoder.decode(encoded_text)\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"Encoded text:\", encoded_text)\n",
    "print(\"Decoded text:\", decoded_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T15:37:15.340760279Z",
     "start_time": "2023-12-01T15:37:15.299318966Z"
    }
   },
   "id": "f1ef49dbcf40a51d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey& is not a valid word.\n",
      "Hello% is not a valid word.\n",
      "ValidWord is a valid word.\n",
      "Another@Word is not a valid word.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r'^[a-zA-Z]+$')\n",
    "\n",
    "# Test the pattern\n",
    "words_to_test = [\"Hey&\", \"Hello%\", \"ValidWord\", \"Another@Word\"]\n",
    "for word in words_to_test:\n",
    "    if pattern.match(word) and '&' not in word and '%' not in word:\n",
    "        print(f\"{word} is a valid word.\")\n",
    "    else:\n",
    "        print(f\"{word} is not a valid word.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-01T16:08:25.263627095Z",
     "start_time": "2023-12-01T16:08:25.213048379Z"
    }
   },
   "id": "c3d56e35a0aaf7cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "49d9c472fee637d9"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "team_names = [\"Team1\", \"Team2\", \"Team3\", \"Team40\"]\n",
    "\n",
    "# Generate random labels for demonstration purposes (replace with actual labels)\n",
    "labels = np.random.randint(0, 2, len(team_names))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:52:15.764906158Z",
     "start_time": "2023-12-02T16:52:15.756815195Z"
    }
   },
   "id": "bc5c2f39dd013108"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 1, 1])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T16:52:17.997722803Z",
     "start_time": "2023-12-02T16:52:17.984484126Z"
    }
   },
   "id": "dc83bd8c6029a36c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping:\n",
      "TeamA -> 0\n",
      "TeamB -> 1\n",
      "TeamC -> 2\n",
      "TeamD -> 3\n",
      "TeamE -> 4\n",
      "TeamF -> 5\n",
      "TeamG -> 6\n",
      "TeamH -> 7\n",
      "TeamI -> 8\n",
      "TeamJ -> 9\n",
      "\n",
      "Encoded label for TeamC: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample list of team names\n",
    "team_names = ['TeamA', 'TeamB', 'TeamC', 'TeamD', 'TeamE', 'TeamF', 'TeamG', 'TeamH', 'TeamI', 'TeamJ']\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the team names to numerical labels\n",
    "encoded_labels = label_encoder.fit_transform(team_names)\n",
    "\n",
    "# Display the mapping between original team names and encoded labels\n",
    "label_mapping = dict(zip(team_names, encoded_labels))\n",
    "print(\"Label Mapping:\")\n",
    "for team, label in label_mapping.items():\n",
    "    print(f\"{team} -> {label}\")\n",
    "\n",
    "# Example usage: Encode a new team name\n",
    "new_team_name = 'TeamC'\n",
    "encoded_label_for_new_team = label_encoder.transform([new_team_name])[0]\n",
    "print(f\"\\nEncoded label for {new_team_name}: {encoded_label_for_new_team}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T17:05:44.608300241Z",
     "start_time": "2023-12-02T17:05:44.320983199Z"
    }
   },
   "id": "ca4805b338d6a3d4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Array 1: [1 2 3 4 5]\n",
      "Loaded Array 2: [[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Sample NumPy arrays\n",
    "array1 = np.array([1, 2, 3, 4, 5])\n",
    "array2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Save arrays to a pickle file\n",
    "with open('arrays.pkl', 'wb') as file:\n",
    "    pickle.dump(array1, file)\n",
    "    pickle.dump(array2, file)\n",
    "\n",
    "# Load arrays from the pickle file\n",
    "with open('arrays.pkl', 'rb') as file:\n",
    "    loaded_array1 = pickle.load(file)\n",
    "    loaded_array2 = pickle.load(file)\n",
    "\n",
    "# Print the loaded arrays\n",
    "print(\"Loaded Array 1:\", loaded_array1)\n",
    "print(\"Loaded Array 2:\", loaded_array2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T06:26:53.820510453Z",
     "start_time": "2023-12-03T06:26:53.782429184Z"
    }
   },
   "id": "31c12248a10549d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
