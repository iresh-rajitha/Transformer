{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pagero 3rd Line GPT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7554e3669af037"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import general libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87db4a4e8a66815f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 12:46:40.301696: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-31 12:46:40.354387: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 12:46:40.709721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-31 12:46:40.709800: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-31 12:46:40.713019: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-31 12:46:40.909816: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 12:46:40.912571: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 12:46:43.109335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sys\n",
    "\n",
    "# !pip install tensorflow==2.11.0\n",
    "# !pip install tensorflow==2.14.0\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# !pip install tensorflow-datasets==4.1.0\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import pdb\n",
    "\n",
    "\n",
    "print(\"Tensorflow version {}\".format(tf.__version__))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T07:16:48.429110084Z",
     "start_time": "2023-10-31T07:16:39.690021611Z"
    }
   },
   "id": "d08504b3a8a299c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize TPU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab0e700ec2116d4e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS: 1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T07:16:48.445335678Z",
     "start_time": "2023-10-31T07:16:48.434653092Z"
    }
   },
   "id": "1009373c8836f288"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### HyperParameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f33e7690dd9ad33b"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ATTEMPT = 1\n",
    "# Maximum sentence length, subject+ description word length\n",
    "MAX_LENGTH = 20 \n",
    "\n",
    "# Maximum number of samples to preprocess\n",
    "MAX_SAMPLES = 70000 # 0 = for All of data otherwise mention the size\n",
    "\n",
    "# Cut off value of words in the dictionary\n",
    "TRESHOLD_VALUE = 1\n",
    "\n",
    "# For tf.data.Dataset\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "BUFFER_SIZE = 20000 #Shuffle data in the dataset\n",
    "\n",
    "# For Transformer\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 16\n",
    "UNITS = 512\n",
    "DROPOUT = 0.3\n",
    "\n",
    "EPOCHS = 4\n",
    "TRAINING_RATIO = 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T07:16:48.486764985Z",
     "start_time": "2023-10-31T07:16:48.442426862Z"
    }
   },
   "id": "9b4ed6a91123e93c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f026b4a50c6ccfe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_set_url = ''"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22581b24e2b21f77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b_data=pd.read_csv( data_set_url , header = None)\n",
    "b_data=b_data.astype(str)\n",
    "# b_data.drop(b_data.columns[[1]], axis = 1, inplace = True)\n",
    "if MAX_SAMPLES == 0 or len(b_data[:][1:]) < MAX_SAMPLES:\n",
    "    b_data = b_data[:][1:]\n",
    "else:\n",
    "    b_data = b_data[:][1:MAX_SAMPLES]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f9abbfa023102de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "test_dataset=[]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "557a5c7d34128778"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set Vocab size"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf724c3cd2d7d540"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f6fed6a4e37995e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feed to transformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d023cec043b1b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from LossFunction import loss_function\n",
    "from transformer.Transformer import transformer\n",
    "from CustomScheduler import CustomSchedule\n",
    "\n",
    "# clear backend\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "# initialize and compile model within strategy scope\n",
    "with strategy.scope():\n",
    "    model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d094da7d76db9f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4fc6eb698093a3e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "history = model.fit(train_dataset, validation_data= test_dataset, epochs=EPOCHS )\n",
    "filename = 'weights.h5'\n",
    "model.save_weights(filename)\n",
    "training_time = time() - start_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed4e884f0a2e44af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ded36b9b86bb23"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y= 0.15\n",
    "r= .02\n",
    "params_print = [\"ACCURACY :\"+ str(history.history['accuracy'][-1]),\n",
    "                \"VAL_ACCURACY :\"+ str(history.history['val_accuracy'][-1]),\n",
    "                \"------ TRANSFORMER---------- :\",\n",
    "                \"UNITS :\"+ str(UNITS),\n",
    "                \"LAYERS :\"+ str(NUM_LAYERS),\n",
    "                \"DROPOUT :\"+ str(DROPOUT),\n",
    "                \"D_MODEL :\"+ str(D_MODEL),\n",
    "                \"NUM_HEADS :\"+ str(NUM_HEADS),\n",
    "                \"------ DATASET---------- :\",\n",
    "                \"BATCH_SIZE :\"+ str(BATCH_SIZE),\n",
    "                \"TRAINING_RATIO :\"+ str(TRAINING_RATIO),\n",
    "                \"BUFFER_SIZE :\"+ str(BUFFER_SIZE),\n",
    "                \"------ TRAINING---------- :\",\n",
    "                \"EPOCHS:\"+ str(EPOCHS),\n",
    "                \"TIME:\"+ str(format(training_time,\".3f\")),\n",
    "                \"TIME:\"+ str(training_time//60)+\" m\"+ str(training_time%60)+\" s\",\n",
    "                \"REPLICAS:\"+ str(strategy.num_replicas_in_sync)\n",
    "                ]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d99e584f2851d9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
